<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Karn Wong ">
<meta name="description" content="Imagine having a dataset that you need to use for training a prediction model, but some of the features are missing. The good news is you don&amp;rsquo;t need to throw some data away, just have to impute them. Below are steps you can take in order to create an imputation pipeline. Github link here!
from random import randint import pandas as pd import numpy as np from sklearn.preprocessing import OneHotEncoder from sklearn." />
<meta name="keywords" content=", data science" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="kahnwong.github.io/posts/2020-05-23-impute-pipelines/" />


    <title>
        
            Impute pipelines :: Karn Wong  â€” Homepage
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="/kahnwong.github.io/main.min.753fac8f03736f0edc9be411eb20cee875dd7bb8e73c8155fbf6a629c863f4ca.css">






<meta itemprop="name" content="Impute pipelines">
<meta itemprop="description" content="Imagine having a dataset that you need to use for training a prediction model, but some of the features are missing. The good news is you don&rsquo;t need to throw some data away, just have to impute them. Below are steps you can take in order to create an imputation pipeline. Github link here!
from random import randint import pandas as pd import numpy as np from sklearn.preprocessing import OneHotEncoder from sklearn.">
<meta itemprop="datePublished" content="2020-05-23T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2020-05-23T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1575">
<meta itemprop="image" content="kahnwong.github.io"/>



<meta itemprop="keywords" content="data science," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="kahnwong.github.io"/>

<meta name="twitter:title" content="Impute pipelines"/>
<meta name="twitter:description" content="Imagine having a dataset that you need to use for training a prediction model, but some of the features are missing. The good news is you don&rsquo;t need to throw some data away, just have to impute them. Below are steps you can take in order to create an imputation pipeline. Github link here!
from random import randint import pandas as pd import numpy as np from sklearn.preprocessing import OneHotEncoder from sklearn."/>







    <meta property="article:published_time" content="2020-05-23 00:00:00 &#43;0000 UTC" />








    </head>

    <body class="dark-theme">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">$ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="kahnwong.github.io/kahnwong.github.io/about">About</a></li><li><a href="kahnwong.github.io/kahnwong.github.io/faq">FAQ</a></li><li><a href="kahnwong.github.io/kahnwong.github.io/posts">Posts</a></li><li><a href="kahnwong.github.io/kahnwong.github.io/resume">Resume</a></li><li><a href="kahnwong.github.io/kahnwong.github.io/tags">Tags</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>8 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title">
                <a href="kahnwong.github.io/posts/2020-05-23-impute-pipelines/">Impute pipelines</a>
            </h1>

            

            <div class="post-content">
                <p>Imagine having a dataset that you need to use for training a prediction model, but some of the features are missing. The good news is you don&rsquo;t need to throw some data away, just have to impute them. Below are steps you can take in order to create an imputation pipeline. Github link <a href="https://github.com/kahnwong/impute-pipelines">here!</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> random <span style="color:#f92672">import</span> randint

<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> OneHotEncoder
<span style="color:#f92672">from</span> sklearn.impute <span style="color:#f92672">import</span> SimpleImputer
<span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> StandardScaler
<span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
<span style="color:#f92672">from</span> sklearn.compose <span style="color:#f92672">import</span> ColumnTransformer
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
<span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeRegressor
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error, median_absolute_error

<span style="color:#f92672">from</span> hyperopt <span style="color:#f92672">import</span> fmin, tpe, hp, Trials, STATUS_OK
<span style="color:#f92672">import</span> mlflow

<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns
sns<span style="color:#f92672">.</span>set()
</code></pre></div><h1 id="generate-data">Generate data</h1>
<p>Since this is an example and I don&rsquo;t want to get sued by using my company&rsquo;s data, synthetic data it is :)</p>
<p>This simulates a dataset from different pseudo-regions, with different characteristics. Real data will be much more varied, but I make it more obvious so it&rsquo;s easy to see the differences.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_array_with_random_nan</span>(lower_bound, upper_bound, size):
    a <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(lower_bound, upper_bound<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, size<span style="color:#f92672">=</span>size)<span style="color:#f92672">.</span>astype(float)
    mask <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>choice([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>], a<span style="color:#f92672">.</span>shape, p<span style="color:#f92672">=</span>[<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">9</span>])<span style="color:#f92672">.</span>astype(bool)
    a[mask] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>nan
    
    <span style="color:#66d9ef">return</span> a

size <span style="color:#f92672">=</span> <span style="color:#ae81ff">6000</span>

df_cbd <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame()
df_cbd[<span style="color:#e6db74">&#39;bed&#39;</span>] <span style="color:#f92672">=</span> generate_array_with_random_nan(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, size)
df_cbd[<span style="color:#e6db74">&#39;bath&#39;</span>] <span style="color:#f92672">=</span> generate_array_with_random_nan(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, size)
df_cbd[<span style="color:#e6db74">&#39;area_usable&#39;</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">40</span>, size<span style="color:#f92672">=</span>size)
df_cbd[<span style="color:#e6db74">&#39;region&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;cbd&#39;</span>

df_suburb <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame()
df_suburb[<span style="color:#e6db74">&#39;bed&#39;</span>] <span style="color:#f92672">=</span> generate_array_with_random_nan(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>, size)
df_suburb[<span style="color:#e6db74">&#39;bath&#39;</span>] <span style="color:#f92672">=</span> generate_array_with_random_nan(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>, size)
df_suburb[<span style="color:#e6db74">&#39;area_usable&#39;</span>] <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">200</span>, size<span style="color:#f92672">=</span>size)
df_suburb[<span style="color:#e6db74">&#39;region&#39;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;suburb&#39;</span>

df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([df_cbd, df_suburb])
df
</code></pre></div><table>
<thead>
<tr>
<th align="right"></th>
<th align="right">bed</th>
<th align="right">bath</th>
<th align="right">area_usable</th>
<th align="left">region</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">33</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">23</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">33</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">26</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">28</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">36</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">6</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">38</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">7</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">23</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">8</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">36</td>
<td align="left">cbd</td>
</tr>
<tr>
<td align="right">9</td>
<td align="right">nan</td>
<td align="right">2</td>
<td align="right">29</td>
<td align="left">cbd</td>
</tr>
</tbody>
</table>
<h1 id="report-missing-values">Report missing values</h1>
<p>I also randomly remove some values to mimic real-world data (read: they are never ready to use), here we will visualize the missing rate of each column.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">report_missing</span>(df):
    cnts <span style="color:#f92672">=</span> []
    cnt_total <span style="color:#f92672">=</span> len(df)
    <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> df<span style="color:#f92672">.</span>columns:
        cnt_missing <span style="color:#f92672">=</span> sum(pd<span style="color:#f92672">.</span>isnull(df[col]) <span style="color:#f92672">|</span> pd<span style="color:#f92672">.</span>isna(df[col]))
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;col: {}, missing: {}%&#34;</span><span style="color:#f92672">.</span>format(col, <span style="color:#ae81ff">100.0</span> <span style="color:#f92672">*</span> cnt_missing <span style="color:#f92672">/</span> cnt_total))

        cnts<span style="color:#f92672">.</span>append({
            <span style="color:#e6db74">&#39;column&#39;</span>: col,
            <span style="color:#e6db74">&#39;missing&#39;</span>: <span style="color:#ae81ff">100.0</span> <span style="color:#f92672">*</span> cnt_missing <span style="color:#f92672">/</span> cnt_total
        })

    cnts_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(cnts)
    sns<span style="color:#f92672">.</span>barplot(x<span style="color:#f92672">=</span>cnts_df<span style="color:#f92672">.</span>missing, 
                y<span style="color:#f92672">=</span>cnts_df<span style="color:#f92672">.</span>column, 
    <span style="color:#75715e">#             palette=[&#39;r&#39;,&#39;b&#39;],</span>
    <span style="color:#75715e">#             data=cnts_df</span>
               )
    
    <span style="color:#66d9ef">return</span> sns

report_missing(df)
</code></pre></div><pre><code>col: bed, missing: 10.266666666666667%
col: bath, missing: 9.616666666666667%
col: area_usable, missing: 0.0%
col: region, missing: 0.0%
</code></pre>
<p><img src="/images/impute-pipelines/pipelines_5_2.png" alt="png"></p>
<h1 id="data-exploration">Data exploration</h1>
<p>Knowing the missing rate isn&rsquo;t everything, thus it is also a good idea to explore data in other areas too.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># missing bed per region</span>
df[df<span style="color:#f92672">.</span>bed<span style="color:#f92672">.</span>isna()][<span style="color:#e6db74">&#34;region&#34;</span>]<span style="color:#f92672">.</span>value_counts(dropna<span style="color:#f92672">=</span>False)
</code></pre></div><pre><code>cbd       634
suburb    598
Name: region, dtype: int64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># missing bath per region</span>
df[df<span style="color:#f92672">.</span>bath<span style="color:#f92672">.</span>isna()][<span style="color:#e6db74">&#34;region&#34;</span>]<span style="color:#f92672">.</span>value_counts(dropna<span style="color:#f92672">=</span>False)
</code></pre></div><pre><code>suburb    588
cbd       566
Name: region, dtype: int64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># explore region</span>
df<span style="color:#f92672">.</span>region<span style="color:#f92672">.</span>value_counts()
</code></pre></div><pre><code>suburb    6000
cbd       6000
Name: region, dtype: int64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># explore bed</span>
df<span style="color:#f92672">.</span>bed<span style="color:#f92672">.</span>value_counts()
</code></pre></div><pre><code>2.0    4050
1.0    4009
4.0    1393
3.0    1316
Name: bed, dtype: int64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># explore bath</span>
df<span style="color:#f92672">.</span>bath<span style="color:#f92672">.</span>value_counts()
</code></pre></div><pre><code>1.0    4142
2.0    4022
3.0    1393
4.0    1289
Name: bath, dtype: int64
</code></pre>
<h1 id="remove-outliers-wouldnt-want-your-model-to-have-a-sub-par-performance-from-skewed-data--p">Remove outliers (wouldn&rsquo;t want your model to have a sub-par performance from skewed data :-P)</h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># remove outliers here</span>
</code></pre></div><h1 id="create-synthetic-columns">Create synthetic columns</h1>
<p>In this step, we create percentile, mean and rank columns to add more data points, so the model can perform better :D</p>
<p>First, we find aggregate percentiles for each groupby set, then add mean and rank columns.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">synth_columns <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;bed&#39;</span>: {
        <span style="color:#e6db74">&#34;region_bath&#34;</span>: [<span style="color:#e6db74">&#39;region&#39;</span>, <span style="color:#e6db74">&#39;bath&#39;</span>]
    },
    <span style="color:#e6db74">&#39;bath&#39;</span>: {
        <span style="color:#e6db74">&#34;region_bed&#34;</span>: [<span style="color:#e6db74">&#39;region&#39;</span>, <span style="color:#e6db74">&#39;bed&#39;</span>]
    }
}

<span style="color:#66d9ef">for</span> column, groupby_levels <span style="color:#f92672">in</span> synth_columns<span style="color:#f92672">.</span>items():
    <span style="color:#66d9ef">for</span> groupby_level_name, groupby_columns <span style="color:#f92672">in</span> groupby_levels<span style="color:#f92672">.</span>items():
        <span style="color:#75715e"># percentile aggregates</span>
        <span style="color:#66d9ef">for</span> pctl <span style="color:#f92672">in</span> [<span style="color:#ae81ff">20</span>,<span style="color:#ae81ff">50</span>,<span style="color:#ae81ff">80</span>,<span style="color:#ae81ff">90</span>]:
            col_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;p{}|{}|{}&#39;</span><span style="color:#f92672">.</span>format(pctl, groupby_level_name, column)
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;calculating -- {}&#34;</span><span style="color:#f92672">.</span>format(col_name))
            df[col_name] <span style="color:#f92672">=</span> df[groupby_columns<span style="color:#f92672">+</span>[column]]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>groupby(groupby_columns)[column]<span style="color:#f92672">.</span>transform(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>quantile(pctl<span style="color:#f92672">/</span><span style="color:#ae81ff">100.0</span>))

        <span style="color:#75715e"># mean impute</span>
        mean_impute <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;mean|{}|{}&#39;</span><span style="color:#f92672">.</span>format(groupby_level_name,column)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;calculating -- {}&#34;</span><span style="color:#f92672">.</span>format(mean_impute))
        df[mean_impute] <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>groupby(groupby_columns)[column]<span style="color:#f92672">.</span>transform(<span style="color:#e6db74">&#39;mean&#39;</span>)
        
        <span style="color:#75715e"># bed/bath rank</span>
        rank_impute <span style="color:#f92672">=</span> column_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;rank|{}|{}&#39;</span><span style="color:#f92672">.</span>format(groupby_level_name,column)
        <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;calculating -- {}&#34;</span><span style="color:#f92672">.</span>format(rank_impute))
        df[rank_impute] <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>groupby(groupby_columns)[column]<span style="color:#f92672">.</span>rank(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;dense&#39;</span>, na_option<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bottom&#39;</span>)

</code></pre></div><pre><code>calculating -- p20|region_bath|bed
calculating -- p50|region_bath|bed
calculating -- p80|region_bath|bed
calculating -- p90|region_bath|bed
calculating -- mean|region_bath|bed
calculating -- rank|region_bath|bed
calculating -- p20|region_bed|bath
calculating -- p50|region_bed|bath
calculating -- p80|region_bed|bath
calculating -- p90|region_bed|bath
calculating -- mean|region_bed|bath
calculating -- rank|region_bed|bath
</code></pre>
<h1 id="coalesce-values">Coalesce values</h1>
<p>In this step we fill in values obtained from the previous step &ndash; impute time!!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">coalesce</span>(df, columns):
    <span style="color:#e6db74">&#39;&#39;&#39;
</span><span style="color:#e6db74">    Implement coalesce of function in colunms.
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Inputs:
</span><span style="color:#e6db74">    df: reference dataframe
</span><span style="color:#e6db74">    columns: columns to perform coalesce
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Returns:
</span><span style="color:#e6db74">    df_tmp: pd.Series that is coalesced
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Example:
</span><span style="color:#e6db74">    df_tmp = pd.DataFrame({&#39;a&#39;: [1,2,None,None,None,None], 
</span><span style="color:#e6db74">                            &#39;b&#39;: [None,6,None,8,9,None], 
</span><span style="color:#e6db74">                            &#39;c&#39;: [None,10,None,12,None,13]})
</span><span style="color:#e6db74">    df_tmp[&#39;new&#39;] = coalesce(df_tmp, [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])
</span><span style="color:#e6db74">    print(df_tmp)
</span><span style="color:#e6db74">    &#39;&#39;&#39;</span>
    df_tmp <span style="color:#f92672">=</span> df[columns[<span style="color:#ae81ff">0</span>]]
    <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> columns[<span style="color:#ae81ff">1</span>:]:
        df_tmp <span style="color:#f92672">=</span> df_tmp<span style="color:#f92672">.</span>fillna(df[c])
    
    <span style="color:#66d9ef">return</span> df_tmp


coalesce_columns <span style="color:#f92672">=</span> [
    <span style="color:#e6db74">&#39;bed&#39;</span>,
    <span style="color:#e6db74">&#39;p50|region_bath|bed&#39;</span>,
    <span style="color:#75715e"># p50|GROUPBY_LESSER_WEIGHT|bed, ...</span>
]

df[<span style="color:#e6db74">&#34;bed_imputed&#34;</span>] <span style="color:#f92672">=</span> coalesce(df, coalesce_columns)

coalesce_columns <span style="color:#f92672">=</span> [
    <span style="color:#e6db74">&#39;bath&#39;</span>,
    <span style="color:#e6db74">&#39;p50|region_bed|bath&#39;</span>,
     <span style="color:#75715e"># p50|GROUPBY_LESSER_WEIGHT|bath, ...</span>
]

df[<span style="color:#e6db74">&#34;bath_imputed&#34;</span>] <span style="color:#f92672">=</span> coalesce(df, coalesce_columns)
</code></pre></div><h1 id="report-missing-values-again">Report missing values (again)</h1>
<p>After we impute the values, let&rsquo;s see how much we are doing better!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">report_missing(df)
</code></pre></div><pre><code>col: bed, missing: 10.266666666666667%
col: bath, missing: 9.616666666666667%
col: area_usable, missing: 0.0%
col: region, missing: 0.0%
col: p20|region_bath|bed, missing: 0.0%
col: p50|region_bath|bed, missing: 0.0%
col: p80|region_bath|bed, missing: 0.0%
col: p90|region_bath|bed, missing: 0.0%
col: mean|region_bath|bed, missing: 9.616666666666667%
col: rank|region_bath|bed, missing: 0.0%
col: p20|region_bed|bath, missing: 0.0%
col: p50|region_bed|bath, missing: 0.0%
col: p80|region_bed|bath, missing: 0.0%
col: p90|region_bed|bath, missing: 0.0%
col: mean|region_bed|bath, missing: 10.266666666666667%
col: rank|region_bed|bath, missing: 0.0%
col: bed_imputed, missing: 0.0%
col: bath_imputed, missing: 0.0%
</code></pre>
<p><img src="/images/impute-pipelines/pipelines_19_2.png" alt="png"></p>
<p>Notice that the imputed columns there are no missing values. Yay!</p>
<h1 id="assign-partition">Assign partition</h1>
<p>In this step, we partition the data into three sets: train, dev and test. Normally we only split into train and test set, but the additional &ldquo;dev&rdquo; set is there so we can make sure it&rsquo;s not too overfit or underfit.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># assign partition</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">assign_partition</span>(x):
    <span style="color:#66d9ef">if</span> x <span style="color:#f92672">in</span> [<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">5</span>]:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">elif</span> x <span style="color:#f92672">in</span> [<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">7</span>]:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># assign random id</span>
df[<span style="color:#e6db74">&#39;listing_id&#39;</span>] <span style="color:#f92672">=</span> [randint(<span style="color:#ae81ff">1000000</span>, <span style="color:#ae81ff">9999999</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(df))]

<span style="color:#75715e"># hashing</span>
df[<span style="color:#e6db74">&#34;hash_id&#34;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#34;listing_id&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: x <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span>)

<span style="color:#75715e"># assign partition</span>
df[<span style="color:#e6db74">&#34;partition_id&#34;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#34;hash_id&#34;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: assign_partition(x))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># define columns group</span>
y_column <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;area_usable&#39;</span>

categ_columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;region&#39;</span>]

numer_columns <span style="color:#f92672">=</span> [
    <span style="color:#e6db74">&#39;bed_imputed&#39;</span>,
    <span style="color:#e6db74">&#39;bath_imputed&#39;</span>,
    
    <span style="color:#e6db74">&#39;p20|region_bath|bed&#39;</span>,
    <span style="color:#e6db74">&#39;p50|region_bath|bed&#39;</span>,
    <span style="color:#e6db74">&#39;p80|region_bath|bed&#39;</span>,
    <span style="color:#e6db74">&#39;p90|region_bath|bed&#39;</span>,
    <span style="color:#e6db74">&#39;mean|region_bath|bed&#39;</span>,
    <span style="color:#e6db74">&#39;rank|region_bath|bed&#39;</span>,
    
    <span style="color:#e6db74">&#39;p20|region_bed|bath&#39;</span>,
    <span style="color:#e6db74">&#39;p50|region_bed|bath&#39;</span>,
    <span style="color:#e6db74">&#39;p80|region_bed|bath&#39;</span>,
    <span style="color:#e6db74">&#39;p90|region_bed|bath&#39;</span>,
    <span style="color:#e6db74">&#39;mean|region_bed|bath&#39;</span>,
    <span style="color:#e6db74">&#39;rank|region_bed|bath&#39;</span>,
]

id_columns <span style="color:#f92672">=</span> [
    <span style="color:#e6db74">&#39;listing_id&#39;</span>,
    <span style="color:#e6db74">&#39;hash_id&#39;</span>,
    <span style="color:#e6db74">&#39;partition_id&#39;</span>
]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># remove missing y</span>
df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>dropna(subset<span style="color:#f92672">=</span>[y_column])

<span style="color:#75715e"># split into train-dev-test</span>
df_train <span style="color:#f92672">=</span> df[df[<span style="color:#e6db74">&#34;partition_id&#34;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]
df_dev <span style="color:#f92672">=</span> df[df[<span style="color:#e6db74">&#34;partition_id&#34;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>]
df_test <span style="color:#f92672">=</span> df[df[<span style="color:#e6db74">&#34;partition_id&#34;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># split each set into x and y</span>
y_train <span style="color:#f92672">=</span> df_train[y_column]<span style="color:#f92672">.</span>values
df_train <span style="color:#f92672">=</span> df_train[numer_columns<span style="color:#f92672">+</span>categ_columns]

y_dev <span style="color:#f92672">=</span> df_dev[y_column]<span style="color:#f92672">.</span>values
df_dev <span style="color:#f92672">=</span> df_dev[numer_columns<span style="color:#f92672">+</span>categ_columns]

y_test <span style="color:#f92672">=</span> df_test[y_column]<span style="color:#f92672">.</span>values
df_test <span style="color:#f92672">=</span> df_test[numer_columns<span style="color:#f92672">+</span>categ_columns]
</code></pre></div><h1 id="create-sklearn-pipelines">Create sklearn pipelines</h1>
<p>In this step, we chain a few pipelines together to process the dataset for the final time. In this example, we use median followed by standard scalar for numeric columns, and mode followed by encoding labels for categorical columns.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># define pipelines</span>
impute_median <span style="color:#f92672">=</span> SimpleImputer(strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;median&#39;</span>)
impute_mode <span style="color:#f92672">=</span> SimpleImputer(strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;most_frequent&#39;</span>)

num_pipeline <span style="color:#f92672">=</span> Pipeline([
        (<span style="color:#e6db74">&#39;impute_median&#39;</span>, impute_median),
        (<span style="color:#e6db74">&#39;std_scaler&#39;</span>, StandardScaler()),
    ])

categ_pipeline <span style="color:#f92672">=</span> Pipeline([
        (<span style="color:#e6db74">&#39;impute_mode&#39;</span>, impute_mode),
        (<span style="color:#e6db74">&#39;categ_1hot&#39;</span>, OneHotEncoder(handle_unknown<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ignore&#39;</span>)),
    ])

full_pipeline <span style="color:#f92672">=</span> ColumnTransformer([
        (<span style="color:#e6db74">&#34;num&#34;</span>, num_pipeline, numer_columns),
        (<span style="color:#e6db74">&#34;cat&#34;</span>, categ_pipeline, categ_columns),
    ])
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># fit and transform</span>
X_train <span style="color:#f92672">=</span> full_pipeline<span style="color:#f92672">.</span>fit_transform(df_train)
X_dev <span style="color:#f92672">=</span> full_pipeline<span style="color:#f92672">.</span>transform(df_dev)
X_test <span style="color:#f92672">=</span> full_pipeline<span style="color:#f92672">.</span>transform(df_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_train
</code></pre></div><pre><code>array([[ 0.04673184,  0.06391404,  0.        , ..., -0.16000115,
         1.        ,  0.        ],
       [-0.97000929, -0.97263688,  0.        , ..., -1.01065389,
         1.        ,  0.        ],
       [ 0.04673184,  0.06391404,  0.        , ..., -0.16000115,
         1.        ,  0.        ],
       ...,
       [-0.97000929,  1.10046497,  0.        , ...,  0.69065159,
         0.        ,  1.        ],
       [ 0.04673184,  1.10046497,  0.        , ...,  0.69065159,
         0.        ,  1.        ],
       [ 1.06347297,  2.13701589,  0.        , ...,  1.54130432,
         0.        ,  1.        ]])
</code></pre>
<h1 id="hyperparameter-tuning">Hyperparameter tuning</h1>
<p>In this step, we try to use different models and parameters to see which performs the best. We utilize mlflow for logging and hyperopt to help with tuning. In this example, we run the trials for 40 iterations, each using a different combination of model and parameters.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># mlflow + hyperopt combo</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">objective</span>(params):
    regressor_type <span style="color:#f92672">=</span> params[<span style="color:#e6db74">&#39;type&#39;</span>]
    <span style="color:#66d9ef">del</span> params[<span style="color:#e6db74">&#39;type&#39;</span>]
    <span style="color:#66d9ef">if</span> regressor_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;gradient_boosting_regression&#39;</span>:
        estimator <span style="color:#f92672">=</span> GradientBoostingRegressor(<span style="color:#f92672">**</span>params)
    <span style="color:#66d9ef">elif</span> regressor_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;random_forest_regression&#39;</span>:
        estimator <span style="color:#f92672">=</span> RandomForestRegressor(<span style="color:#f92672">**</span>params)
    <span style="color:#66d9ef">elif</span> regressor_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;extra_trees_regression&#39;</span>:
        estimator <span style="color:#f92672">=</span> ExtraTreesRegressor(<span style="color:#f92672">**</span>params)
    <span style="color:#66d9ef">elif</span> regressor_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;decision_tree_regression&#39;</span>:
        estimator <span style="color:#f92672">=</span> DecisionTreeRegressor(<span style="color:#f92672">**</span>params)
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>    
    
    estimator<span style="color:#f92672">.</span>fit(X_train, y_train)
    
    <span style="color:#75715e"># mae    </span>
    y_dev_hat <span style="color:#f92672">=</span> estimator<span style="color:#f92672">.</span>predict(X_dev)
    mae <span style="color:#f92672">=</span> median_absolute_error(y_dev, y_dev_hat)
    
    <span style="color:#75715e"># logging</span>
    <span style="color:#66d9ef">with</span> mlflow<span style="color:#f92672">.</span>start_run():
        mlflow<span style="color:#f92672">.</span>log_param(<span style="color:#e6db74">&#34;regressor&#34;</span>, estimator<span style="color:#f92672">.</span>__class__<span style="color:#f92672">.</span>__name__)
        <span style="color:#75715e"># mlflow.log_param(&#34;params&#34;, params)</span>
        mlflow<span style="color:#f92672">.</span>log_param(<span style="color:#e6db74">&#39;n_estimators&#39;</span>, params<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;n_estimators&#39;</span>))
        mlflow<span style="color:#f92672">.</span>log_param(<span style="color:#e6db74">&#39;max_depth&#39;</span>, params<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;max_depth&#39;</span>))
        
        mlflow<span style="color:#f92672">.</span>log_metric(<span style="color:#e6db74">&#34;median_absolute_error&#34;</span>, mae)  
    
    <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#39;loss&#39;</span>: mae, <span style="color:#e6db74">&#39;status&#39;</span>: STATUS_OK}

space <span style="color:#f92672">=</span> hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;regressor_type&#39;</span>, [    
    {
        <span style="color:#e6db74">&#39;type&#39;</span>: <span style="color:#e6db74">&#39;gradient_boosting_regression&#39;</span>,
        <span style="color:#e6db74">&#39;n_estimators&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;n_estimators1&#39;</span>, range(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">200</span>,<span style="color:#ae81ff">50</span>)),
        <span style="color:#e6db74">&#39;max_depth&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;max_depth1&#39;</span>, range(<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">13</span>,<span style="color:#ae81ff">1</span>))
    },
    {
        <span style="color:#e6db74">&#39;type&#39;</span>: <span style="color:#e6db74">&#39;random_forest_regression&#39;</span>,
        <span style="color:#e6db74">&#39;n_estimators&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;n_estimators2&#39;</span>, range(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">200</span>,<span style="color:#ae81ff">50</span>)),
        <span style="color:#e6db74">&#39;max_depth&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;max_depth2&#39;</span>, range(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">1</span>)),
        <span style="color:#e6db74">&#39;n_jobs&#39;</span>: <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
        
    },
    {
        <span style="color:#e6db74">&#39;type&#39;</span>: <span style="color:#e6db74">&#39;extra_trees_regression&#39;</span>,
        <span style="color:#e6db74">&#39;n_estimators&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;n_estimators3&#39;</span>, range(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">200</span>,<span style="color:#ae81ff">50</span>)),
        <span style="color:#e6db74">&#39;max_depth&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;max_depth3&#39;</span>, range(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">2</span>))
    },
    {
        <span style="color:#e6db74">&#39;type&#39;</span>: <span style="color:#e6db74">&#39;decision_tree_regression&#39;</span>,
        <span style="color:#e6db74">&#39;max_depth&#39;</span>: hp<span style="color:#f92672">.</span>choice(<span style="color:#e6db74">&#39;max_depth4&#39;</span>, range(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">10</span>,<span style="color:#ae81ff">2</span>))
    }
])

trials <span style="color:#f92672">=</span> Trials()
max_evals <span style="color:#f92672">=</span> <span style="color:#ae81ff">40</span>

best <span style="color:#f92672">=</span> fmin(
fn<span style="color:#f92672">=</span>objective, 
space<span style="color:#f92672">=</span>space,
algo<span style="color:#f92672">=</span>tpe<span style="color:#f92672">.</span>suggest,
max_evals<span style="color:#f92672">=</span>max_evals,
trials<span style="color:#f92672">=</span>trials)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Found minimum after {} trials:&#34;</span><span style="color:#f92672">.</span>format(max_evals))
<span style="color:#f92672">from</span> pprint <span style="color:#f92672">import</span> pprint
pprint(best)
</code></pre></div><pre><code>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:19&lt;00:00,  2.11trial/s, best loss: 8.569474762575908]
Found minimum after 40 trials:
{'max_depth2': 1, 'n_estimators2': 1, 'regressor_type': 1}
</code></pre>
<h1 id="evaluate-performance">Evaluate performance</h1>
<p>Run &ldquo;mlflow server&rdquo; to see the loggin dashboard. There, we can see that RandomForestRegressor has the best performance (the less MAE the better) when using max_depth=4  and n_estimators=150, to test the model&rsquo;s performance against another test set:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># use best params on TEST set</span>
estimator <span style="color:#f92672">=</span> RandomForestRegressor(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>)
estimator<span style="color:#f92672">.</span>fit(X_train, y_train)
    
y_train_hat <span style="color:#f92672">=</span> estimator<span style="color:#f92672">.</span>predict(X_train)
train_mae <span style="color:#f92672">=</span> median_absolute_error(y_train, y_train_hat)

y_dev_hat <span style="color:#f92672">=</span> estimator<span style="color:#f92672">.</span>predict(X_dev)
dev_mae <span style="color:#f92672">=</span> median_absolute_error(y_dev, y_dev_hat)

y_test_hat <span style="color:#f92672">=</span> estimator<span style="color:#f92672">.</span>predict(X_test)
test_mae <span style="color:#f92672">=</span> median_absolute_error(y_test, y_test_hat)

mae <span style="color:#f92672">=</span>  {
    <span style="color:#e6db74">&#39;name&#39;</span>: estimator<span style="color:#f92672">.</span>__class__<span style="color:#f92672">.</span>__name__,
    <span style="color:#e6db74">&#39;train_mae&#39;</span>: train_mae,
    <span style="color:#e6db74">&#39;dev_mae&#39;</span>: dev_mae,
    <span style="color:#e6db74">&#39;test_mae&#39;</span>: test_mae
}

mae <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame([mae])<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;name&#39;</span>)

mae
</code></pre></div><table>
<thead>
<tr>
<th align="left">name</th>
<th align="right">train_mae</th>
<th align="right">dev_mae</th>
<th align="right">test_mae</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">DecisionTreeRegressor</td>
<td align="right">8.930245</td>
<td align="right">8.592484</td>
<td align="right">8.729826</td>
</tr>
</tbody>
</table>
<p>You&rsquo;ll notice that we use &ldquo;median absolute error&rdquo; to measure performance. There are other metrics available, such as mean squared error, but in some cases it&rsquo;s more meaningful to use a metric that measure the performance in actual data&rsquo;s unit, in this case the error on dev and test set are around 8 units away from its correct value. Since normally we use square meter for area, it means the prediction will be off by about 8 square meters in most cases.</p>

            </div>
        </article>

        <hr />

        <div class="post-info">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="kahnwong.github.io/tags/data-science">data science</a></span>
                </p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1575 Words</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2020-05-23 07:00 &#43;0700</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h">Read other posts</span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    

                    
                        <span class="button next">
                            <a href="kahnwong.github.io/posts/2020-04-16-word-based-analysis-with-song-lyrics/">
                                <span class="button__text">Word-based analysis with song lyrics</span>
                                <span class="button__icon">â†’</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2020</span>
            
                <span><a href="kahnwong.github.io">Karn Wong</a></span>
            
            <span></span>
            <span> <a href="kahnwong.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></span>
        </div>
    </div>
    <div class="footer__inner">
        <div class="footer__content">
            <span>Powered by <a href="http://gohugo.io">Hugo</a></span>
            <span>Made with &#10084; by <a href="https://github.com/rhazdon">Djordje Atlialp</a></span>
        </div>
    </div>
</footer>

            
        </div>

        




<script type="text/javascript" src="/kahnwong.github.io/bundle.min.4a69500057d68129e88f497d354afe68422eb56de6d15e45dbe2190858ea5a76bfcb096406f992984b241db45f47388ac57ab0376e3b32125bef7a8a6d0f06c4.js" integrity="sha512-SmlQAFfWgSnoj0l9NUr&#43;aEIutW3m0V5F2&#43;IZCFjqWna/ywlkBvmSmEskHbRfRziKxXqwN247MhJb73qKbQ8GxA=="></script>



    </body>
</html>
